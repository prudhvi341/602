{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10 - PCA and Dimension Reduction Homework\n",
    "Execute the below code and answer the following questions. __Do NOT commit the csv file!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "def generate_data():\n",
    "    x, y = make_classification(n_samples=1500, \n",
    "                            n_features = 20,\n",
    "                            n_informative = 8,\n",
    "                            n_redundant = 5,\n",
    "                            n_repeated = 1, \n",
    "                            n_classes = 3,\n",
    "                            weights = (0.5, 0.25, 0.25),\n",
    "                            random_state = 120\n",
    "                            )\n",
    "    colNames = ['var'+str(x) for x in range(20)]\n",
    "    colNames.append('target')\n",
    "\n",
    "    df = pd.DataFrame(np.concatenate((x,y.reshape(-1,1)), axis=1), columns=colNames)\n",
    "    df.to_csv('pca-dataset.csv', index=False)\n",
    "    \n",
    "generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var0</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var9</th>\n",
       "      <th>...</th>\n",
       "      <th>var11</th>\n",
       "      <th>var12</th>\n",
       "      <th>var13</th>\n",
       "      <th>var14</th>\n",
       "      <th>var15</th>\n",
       "      <th>var16</th>\n",
       "      <th>var17</th>\n",
       "      <th>var18</th>\n",
       "      <th>var19</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.882513</td>\n",
       "      <td>-3.272465</td>\n",
       "      <td>-2.520732</td>\n",
       "      <td>-1.987174</td>\n",
       "      <td>-2.073689</td>\n",
       "      <td>-3.272465</td>\n",
       "      <td>-1.237969</td>\n",
       "      <td>1.690547</td>\n",
       "      <td>-0.211314</td>\n",
       "      <td>-5.753190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.574979</td>\n",
       "      <td>-1.916275</td>\n",
       "      <td>-5.994075</td>\n",
       "      <td>-3.349615</td>\n",
       "      <td>-0.846193</td>\n",
       "      <td>2.491347</td>\n",
       "      <td>1.360958</td>\n",
       "      <td>-2.892522</td>\n",
       "      <td>-1.377561</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.775242</td>\n",
       "      <td>-1.015994</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>0.057274</td>\n",
       "      <td>0.590205</td>\n",
       "      <td>-1.015994</td>\n",
       "      <td>1.350954</td>\n",
       "      <td>-1.493037</td>\n",
       "      <td>-0.862391</td>\n",
       "      <td>-1.986047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523760</td>\n",
       "      <td>0.399579</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.718606</td>\n",
       "      <td>-1.112030</td>\n",
       "      <td>0.083929</td>\n",
       "      <td>0.606544</td>\n",
       "      <td>-1.376793</td>\n",
       "      <td>1.302641</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.876376</td>\n",
       "      <td>0.220453</td>\n",
       "      <td>3.114224</td>\n",
       "      <td>-1.640025</td>\n",
       "      <td>1.180348</td>\n",
       "      <td>0.220453</td>\n",
       "      <td>0.465102</td>\n",
       "      <td>0.222511</td>\n",
       "      <td>0.880455</td>\n",
       "      <td>2.922315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.370516</td>\n",
       "      <td>3.585262</td>\n",
       "      <td>-2.168162</td>\n",
       "      <td>2.693429</td>\n",
       "      <td>-0.966636</td>\n",
       "      <td>1.586302</td>\n",
       "      <td>-2.821546</td>\n",
       "      <td>0.482164</td>\n",
       "      <td>0.187404</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.550342</td>\n",
       "      <td>-1.968144</td>\n",
       "      <td>0.077681</td>\n",
       "      <td>-1.887719</td>\n",
       "      <td>1.864445</td>\n",
       "      <td>-1.968144</td>\n",
       "      <td>-0.527958</td>\n",
       "      <td>-0.201467</td>\n",
       "      <td>-0.532649</td>\n",
       "      <td>2.287445</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041341</td>\n",
       "      <td>2.383582</td>\n",
       "      <td>-0.417253</td>\n",
       "      <td>1.305379</td>\n",
       "      <td>-0.435123</td>\n",
       "      <td>-0.468557</td>\n",
       "      <td>0.923290</td>\n",
       "      <td>3.880050</td>\n",
       "      <td>2.676798</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.454974</td>\n",
       "      <td>1.293300</td>\n",
       "      <td>0.112201</td>\n",
       "      <td>-0.589989</td>\n",
       "      <td>-1.674321</td>\n",
       "      <td>1.293300</td>\n",
       "      <td>0.487302</td>\n",
       "      <td>1.776318</td>\n",
       "      <td>0.702520</td>\n",
       "      <td>-1.024127</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452869</td>\n",
       "      <td>-0.667306</td>\n",
       "      <td>0.345364</td>\n",
       "      <td>-3.920591</td>\n",
       "      <td>-0.438296</td>\n",
       "      <td>-1.690141</td>\n",
       "      <td>0.176906</td>\n",
       "      <td>1.920142</td>\n",
       "      <td>1.474634</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var0      var1      var2      var3      var4      var5      var6  \\\n",
       "0 -2.882513 -3.272465 -2.520732 -1.987174 -2.073689 -3.272465 -1.237969   \n",
       "1  0.775242 -1.015994  0.005137  0.057274  0.590205 -1.015994  1.350954   \n",
       "2 -0.876376  0.220453  3.114224 -1.640025  1.180348  0.220453  0.465102   \n",
       "3 -2.550342 -1.968144  0.077681 -1.887719  1.864445 -1.968144 -0.527958   \n",
       "4 -0.454974  1.293300  0.112201 -0.589989 -1.674321  1.293300  0.487302   \n",
       "\n",
       "       var7      var8      var9  ...     var11     var12     var13     var14  \\\n",
       "0  1.690547 -0.211314 -5.753190  ... -0.574979 -1.916275 -5.994075 -3.349615   \n",
       "1 -1.493037 -0.862391 -1.986047  ...  0.523760  0.399579  0.088600  0.718606   \n",
       "2  0.222511  0.880455  2.922315  ... -0.370516  3.585262 -2.168162  2.693429   \n",
       "3 -0.201467 -0.532649  2.287445  ... -0.041341  2.383582 -0.417253  1.305379   \n",
       "4  1.776318  0.702520 -1.024127  ... -0.452869 -0.667306  0.345364 -3.920591   \n",
       "\n",
       "      var15     var16     var17     var18     var19  target  \n",
       "0 -0.846193  2.491347  1.360958 -2.892522 -1.377561     0.0  \n",
       "1 -1.112030  0.083929  0.606544 -1.376793  1.302641     2.0  \n",
       "2 -0.966636  1.586302 -2.821546  0.482164  0.187404     0.0  \n",
       "3 -0.435123 -0.468557  0.923290  3.880050  2.676798     1.0  \n",
       "4 -0.438296 -1.690141  0.176906  1.920142  1.474634     0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('pca-dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 21 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   var0    1500 non-null   float64\n",
      " 1   var1    1500 non-null   float64\n",
      " 2   var2    1500 non-null   float64\n",
      " 3   var3    1500 non-null   float64\n",
      " 4   var4    1500 non-null   float64\n",
      " 5   var5    1500 non-null   float64\n",
      " 6   var6    1500 non-null   float64\n",
      " 7   var7    1500 non-null   float64\n",
      " 8   var8    1500 non-null   float64\n",
      " 9   var9    1500 non-null   float64\n",
      " 10  var10   1500 non-null   float64\n",
      " 11  var11   1500 non-null   float64\n",
      " 12  var12   1500 non-null   float64\n",
      " 13  var13   1500 non-null   float64\n",
      " 14  var14   1500 non-null   float64\n",
      " 15  var15   1500 non-null   float64\n",
      " 16  var16   1500 non-null   float64\n",
      " 17  var17   1500 non-null   float64\n",
      " 18  var18   1500 non-null   float64\n",
      " 19  var19   1500 non-null   float64\n",
      " 20  target  1500 non-null   float64\n",
      "dtypes: float64(21)\n",
      "memory usage: 246.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['var0', 'var1', 'var2', 'var3', 'var4', 'var5', 'var6', 'var7', 'var8',\n",
       "       'var9', 'var10', 'var11', 'var12', 'var13', 'var14', 'var15', 'var16',\n",
       "       'var17', 'var18', 'var19', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1,200\n",
      "Test samples: 300\n",
      "\n",
      "Features:\n",
      "var0\tvar1\tvar2\tvar3\tvar4\tvar5\tvar6\tvar7\tvar8\tvar9\tvar10\tvar11\tvar12\tvar13\tvar14\tvar15\tvar16\tvar17\tvar18\tvar19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[[x for x in df.columns if x.startswith('var')]]\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "print(f'Training samples: {X_train.shape[0]:,}')\n",
    "print(f'Test samples: {X_test.shape[0]:,}')\n",
    "\n",
    "print('\\nFeatures:')\n",
    "print(*X_train, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "- `var1 - var19`: a feature for the data.  \n",
    "- `target`: variable we wish to be able to predict, which is 1 of 3 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "- Use principle components analysis to determine the number of components to reduce the data to by evaluating the explained variance ratio (use `X_train`).  \n",
    "- Remember to scale the data first.  \n",
    "- What number of components would you recommend based on your analysis?  \n",
    "- Explain your results using markdown cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Standardising the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.78248763e-01 1.31423463e-01 1.03428992e-01 8.93001375e-02\n",
      " 7.00271587e-02 6.26207004e-02 5.53463463e-02 5.16479599e-02\n",
      " 4.98606225e-02 4.86667259e-02 4.67744196e-02 4.42653499e-02\n",
      " 4.16638974e-02 2.67254645e-02 1.59179548e-32 8.46282432e-33\n",
      " 3.76790393e-33 2.35893417e-33 2.00189072e-33 7.02250978e-34]\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA\n",
    "pca = PCA()\n",
    "pca.fit(X_train_scaled)\n",
    "\n",
    "# Evaluate the explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(explained_variance_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAArwElEQVR4nO3dd5wV1f3/8deHLkgVLHQEhCAK4gI2FFuCFVuiqBGxRUVi9KvRRGNN/GmMiTUSNCoGUGPBoMEuWKIgsHSQKsLSEel1dz+/P2bQ67plFnZ27u59Px+Pfey0O/O5w2U/95wz5xxzd0REJHNVSToAERFJlhKBiEiGUyIQEclwSgQiIhlOiUBEJMNVSzqA0mrcuLG3bt066TBERCqUSZMmrXH3JoXtq3CJoHXr1kycODHpMEREKhQz+7qofaoaEhHJcEoEIiIZTolARCTDKRGIiGQ4JQIRkQwXWyIws2fMbJWZzShiv5nZo2Y238ymmVm3uGIREZGixVkieA7oU8z+U4D24c9VwJMxxiIiIkWIrR+Bu39sZq2LOaQv8LwH42CPM7MGZnaAuy+PKyYR2T3L1m3lzWnL2LQtN+lQMlpW60Yce1ChfcL2SJIdypoBS1LWc8JtP0oEZnYVQamBli1blktwIpkuL98ZO2cVI8YvZsycVeQ7mCUdVWa7+ri2lS4RFPaRKnSWHHcfAgwByMrK0kw6IjFavn4rL01YwksTlrB8/Taa1K3JNb3bckH3lrRoVDvp8CQGSSaCHKBFynpzYFlCsYhktLx856O5qxgxfgkffrmSfIde7Rtz5xmdOPEn+1G9qh4wrMySTASjgOvM7EWgJ7Be7QMi5WvF+m38e2Lw7X/puq003rsmVx8XfPtvuY++/WeK2BKBmb0A9AYam1kOcCdQHcDdBwOjgVOB+cAWYEBcsYjI9/LynY/nrWbE+MV8+OUq8vKdXu0bc9tpP+Gkn+xHjWr69p9p4nxqqF8J+x0YGNf1ReSHVm3YxksTlvBi+O1/nzo1uLLXgfTr0YJW+9RJOjxJUIUbhlpESmd7bh5Pjl3A38csYEdePke324ffndqRn3baX9/+BVAiEKnUPl/wDbeNnM7CNZs5o0tTbjz5INo01rd/+SElApFKaO3mHdw3ejavTMqhRaO9GHpZD46L4flzqRyUCEQqEXfn1eyl/Om/s9i4LZdre7dl0Ant2atG1aRDkzSmRCBSSSxYvYnbRk5n3MK1HN6qIfedfQgd9q+bdFhSAZSYCMysPnAX0Cvc9BFwj7uvjzEuEYloe24eg8cu5Ikx86lZvQr3nX0IF3RvQZUqGg9CoolSIngGmAH8Ilz/JfAscE5cQYlINOMWfsPvR05n4eqgMfgPp/+EfevWSjosqWCiJIK27n5uyvrdZjYlpnhEJIJvw8bgl8PG4OcGdKd3h32TDksqqCiJYKuZHePunwKY2dHA1njDEpHCuDuvZS/lT6Nns2HrTq7p3ZZfqzFY9lCURHANMDRsKzBgLXBpnEGJyI8tXL2J21+fwWcLvqFbywbcd84hdNy/XtJhSSVQYiJw9ylAFzOrF65viDsoEflebl4+T3/6FX99by41q1Xhj2d15sIeLdUYLGWmyERgZhe7+zAzu7HAdgDc/a8xxyaS8eat3MhNr0xj6pJ1/Ozg/bi3b2f2rafGYClbxZUIdvVDL+xBZE0OIxKj3Lx8hnyykIffm0edmlV5rN9hnH7oAd99ERMpS0UmAnf/R7j4vrv/L3Vf2GAsIjGYu3IjN788lak56+lz8P7ce1ZnmtStmXRYUolFaSx+DOgWYZuI7IHcvHz+8fFCHnl/HnvXqsbjFx7GaYeoFCDxK66N4EjgKKBJgXaCeoCeVRMpQ3NWbOTmV6YyLWc9px6yP/f07UzjvVUKkPJRXImgBrB3eExqO8EG4Lw4gxLJFKmlgLq1qvHEhd047dADkg5LMkxxbQQfAR+Z2XPu/nU5xiSSEb5csYGbX57G9KXrOe3QA7jnzIPZR6UASUCUNoItZvYgcDDw3XNr7n5CbFGJVGI78/IZPHYBj344j3q1qvP3i7px6iEqBUhyoiSC4cBLwOnA1UB/YHWcQYlUVrOXb+DmV6YyY+kGzujSlLvPPJhGdWokHZZkuCiJYB93/6eZXZ9SXfRR3IGJVCY78/J5cuwCHvtwHvX3qs7gi7vRp7NKAZIeoiSCneHv5WZ2GrAMaB5fSCKVy1drNnPDS1OYsmSdSgGSlqIkgj+GA879H0H/gXrADbFGJVIJuDsvTljCPW/Moka1Kjx+4WGcfmjTpMMS+ZFiE4GZVQXau/ubwHrg+HKJSqSC+2bTdm55dTrvz17JMe0a85efd2H/+hojSNJTsYnA3fPM7Ezgb+UUj0iFN+bLVdz8yjQ2bNvJH07vxICjWmukUElrUaqGPjOzxwmeHNq8a6O7Z8cWlUgFtHVHHn8aPYth4xbTcf+6DLuih+YLkAohSiI4Kvx9T8o2B9SPQCQ0LWcdv3lpCgtXb+bKXm34v592oFZ1jcQiFUOUiWnULiBShLx8Z/BHC/jbe3NpvHdNRlzRk6PaNU46LJFSiVIiEJFCLFm7hRtemsLEr7/l9EMP4E9nHUL92tWTDkuk1JQIRErJ3Xk1eyl3jZqJAQ+f35W+XZtquGipsJQIRErh2807uO316YyevoIebRrx1190oXnD2kmHJbJHSkwEZlaboDNZS3e/0szaAx3CvgUiGeOTeau56eWprN28g1tP6ciVvQ6kqh4LlUogSongWWAScGS4ngO8DCgRSEbYkZvPX96dw5CPF9Ju3735Z//udG5WP+mwRMpMlETQ1t3PN7N+AO6+1VQZKhni62828+sXJjM1Zz0XH9GS207txF419FioVC5REsEOM9uLoO8AZtYW2B5rVCJp4D9TlnLbyBlUMTRaqFRqURLBncDbQAszGw4cDVwaZ1AiSdq8PZc7R83klUk5ZLVqyMMXdFWDsFRqUTqUvWdm2cARgAHXu/ua2CMTScDMZesZ9MJkvlqzmV+f0I5fn9iealWrJB2WSKyiPDV0NvChu/83XG9gZme5++txBydSXtydoZ8t4r7RX9KwTnWGX9GTo9qqh7BkhkhVQ+4+cteKu68zszuB12OLSqQcfbt5Bze/Mo33Z6/kxI778uDPu2jiGMkoUcq8hR0TqSOamfUxszlmNt/Mbi1kf30ze8PMpprZTDMbEOW8ImVl3MJvOOWRT/h47mruPKMTT/fPUhKQjBPlD/pEM/sr8ATBk0ODCPoVFCuc1OYJ4GSCvgcTzGyUu89KOWwgMMvdzzCzJsAcMxvu7jtK+0ZESiM3L59HP5zP4x/Oo9U+dXit/1HqGyAZK0oiGAT8gWA+AgPeJfgDXpIewHx3XwhgZi8CfYHUROBA3bBfwt7AWiA3cvQiu2HZuq385sUpfLFoLed2a849fQ+mTk2NtiKZK8pTQ5uBH1XrRNAMWJKyngP0LHDM48AoYBlQFzjf3fMLnsjMrgKuAmjZsuVuhCISeGfmCn77yjRy8/J5+PyunHVYs6RDEklclKeGDgJuAlqnHu/uJU1MU1jvYy+w/jNgCsEkN22B98zsE3ff8IMXuQ8BhgBkZWUVPIdIibbtzOO+0bN5/vOvOaRZfR7rdxitG9dJOiyRtBClPPwyMBh4GsgrxblzgBYp680JvvmnGgDc7+4OzDezr4COwBeluI5Isb5as5mBw7OZtXwDV/Zqw80/60iNauobILJLlESQ6+5P7sa5JwDtzawNsBS4ALiwwDGLgROBT8xsP6ADsHA3riVSqDemLuN3r02nWlXjmUuzOKHjfkmHJJJ2oiSCN8zsWmAkKWMMufva4l7k7rlmdh3wDlAVeMbdZ5rZ1eH+wcC9wHNmNp2gKukW9VqWsrBtZx73vjmL4eMXc3irhjzW7zCaNtgr6bBE0pIFtTLFHBBU1xTk7n5gPCEVLysryydOnJjEpaWCWLh6EwNHTGb28g1cfVxb/u+nB1Fdw0RIhjOzSe6eVdi+KE8NtSn7kETi8Z8pS/n9a9OpUa0Kz17aneM77pt0SCJpL2oP4c5AJ6DWrm3u/nxcQYmU1radedz9xixe+GIxWa0a8qiqgkQii/L46J1Ab4JEMBo4BfgUUCKQtLBg9SYGDs/myxUbuaZ3W248WVVBIqURpURwHtAFmOzuA8Kne56ONyyRaH5QFTSgO8d3UFWQSGlFSQRb3T3fzHLNrB6wCkikoVhkl6AqaCYvfLGE7q2DqqAD6qsqSGR3RB10rgHwFMFgc5tQhy9J0PxVm7huRFAVdG1YFaTJY0R2X5Snhq4NFweb2dtAPXefFm9YIoV7ffJSfj9yOrWqV+W5Ad3praogkT1WZCIws47u/qWZdStkXzd3z443NJHvbduZx12jZvLihCX0aN2IR/sdxv71a5X8QhEpUXElghsJRvx8qJB9TjBQnEjsFn+zhauHTWLW8g2qChKJQZGJwN2vMrMqwO3u/r9yjEnkOx/MXskNL03BzNRBTCQmxbYRhE8L/QU4spziEQEgL9/523tzeXzMfA5uWo/BFx9Oi0a1kw5LpFKK8tTQu2Z2LvCalzQwkUgZ+GbTdq5/cQqfzl/D+VktuLvvwdSqXjXpsEQqrSiJ4EagDpBrZtsIRgl1d68Xa2SSkSYv/paBw7NZs3kHD5x7COd314x0InGL8vho3fIIRDKbuzNs3Nfc8+Ys9qtXi9eu0WTyIuUl6qBzDYH2/HDQuY/jCkoyy5Ydudw2cgYjJy/l+A5N+Nv5XWlQu0bSYYlkjCiDzl0BXE8w1eQU4Ajgc/T4qJSBhas3cc2wbOau2siNJx/Edce3o0qVwqa7FpG4RCkRXA90B8a5+/Fm1hG4O96wJBO8PWMFN788lWpVjaEDenDsQU2SDkkkI0VJBNvcfZuZYWY1w97GHWKPTCqt3Lx8Hnx3Dv/4aCFdmtfniYu60byhHg0VSUqURJATDjr3OvCemX0LLIszKKm8Vm/czqAXshm3cC0X9WzJHWd0omY1PRoqkqQoTw2dHS7eZWZjgPrA27FGJZXSxEVruXZ4Nuu37uShn3fh3MObJx2SiBCtsfgR4CV3/8zdPyqHmKQSGj7+a+78z0yaNdyL5wb0oFNTdUMRSRdRqoaygdvN7CBgJEFSmBhvWFJZ5Oblc++bsxj6+df07tCERy44jPp7VU86LBFJEaVqaCgw1MwaAecCD5hZS3dvH3t0UqGt37KTgSOy+XT+Gq44pg2/O/UnVNWjoSJpJ1KHslA7oCPQGpgVSzRSaSxcvYkrhk5kybdbNFSESJqL0kbwAHAOsAB4CbjX3dfFHJdUYJ/OW8O1wydRrWoVhl3ek54H7pN0SCJSjCglgq+AI919TdzBSMX3/OeLuPuNWbRtUod/9u+uoaNFKoAobQSDyyMQqdh25uVz9xszGTZuMSd23JeHL+hK3VpqFBapCErTRiBSqHVbdnDt8Gw+W/ANvzr2QH7bp6MahUUqECUC2SPzV23iiqETWLZuGw+edyg/z2qRdEgiUkpFJoLwcdEiufvasg9HKpKP5q7muhHZ1KhahRFX9iSrdbEfGRFJU8WVCCYBTjAjWUvg23C5AbAYaBN3cJKe3J1n/7eIP/53FgftV5en+2dp0DiRCqzIRODubQDMbDAwyt1Hh+unACeVT3iSbnbk5nPnqBm88MUSTu60Hw+f35U6NVXDKFKRRfkf3N3dr9614u5vmdm9McYkaerbzTu4etgkxn+1lmt7t+Wmn3bQJDIilUCURLDGzG4HhhFUFV0MfBNrVJJ2vlqzmf7PfMGKDdt4+PyunHVYs6RDEpEyEiUR9APuJBhwzoGPw22SIWYv38Av//kF+e68eNURdGvZMOmQRKQMRelQtha43sz2dvdN5RCTpJHsxd9y6TNfULtGNYZd0ZN2+9ZNOiQRKWNVSjrAzI4ys1mEA82ZWRcz+3vskUni/jd/DRc/PZ6GdWrw8tVHKgmIVFIlJgLgb8DPCNsF3H0qcGycQUny3p25ggHPTqBFw9q8/KsjNWaQSCUW6bk/d19i9oOnQ/LiCUfSweuTl/J/L0+lc7P6DB3QnQa1ayQdkojEKEqJYImZHQW4mdUws5uA2VFObmZ9zGyOmc03s1uLOKa3mU0xs5lmpqkwE/avzxdxw7+n0L11Q4Zf0VNJQCQDRCkRXA08AjQDcoB3gYElvcjMqgJPACeHr5tgZqPcfVbKMQ2AvwN93H2xme1b6ncgZebvY+fz57fncGLHfXniom7Uql416ZBEpBxEeWpoDXDRbpy7BzDf3RcCmNmLQF9+OLvZhcBr7r44vNaq3biO7CF354G35zD4owWc2aUpD/2iC9WrRiksikhlEGWGsibAlQRTVH53vLtfVsJLmwFLUtZzgJ4FjjkIqG5mY4G6wCPu/nwhMVwFXAXQsqWmPCxL+fnOHaNmMGzcYi7s2ZJ7+3bWENIiGSZK1dB/gE+A9yldI3Fhf028kOsfDpwI7AV8bmbj3H3uD17kPgQYApCVlVXwHLKbdublc/PLU3l9yjJ+ddyB3NqnIwUeChCRDBAlEdR291t249w5QOrg9M2BZYUcs8bdNwObzexjoAswF4nVtp15XDdiMu/PXsnNP+vAtb3bKgmIZKgoFcFvmtmpu3HuCUB7M2tjZjWAC4BRBY75D9DLzKqZWW2CqqNITyTJ7tu8PZfLnpvA+7NXck/fgxl4fDslAZEMFqVEcD3wezPbDuwkqPJxd69X3IvcPdfMrgPeAaoCz7j7TDO7Otw/2N1nm9nbwDQgH3ja3WfswfuREqzbsoNLn53A9KXr+esvunBOt+ZJhyQiCTP3ilXlnpWV5RMnTkw6jApp1cZtXPLPL1i4ejOP9juMPp33TzokESknZjbJ3bMK21fcVJUd3f1LM+tW2H53zy6rACV+y9dvpd+QcazcsJ1/XppFr/ZNkg5JRNJEcVVDNxI8svlQIfscOCGWiKTMrdm0nYueHs+aTTsYdkUPDm+luYVF5HvFTVV5Vfj7+PILR8raui07uPjp8Sxbt5XnL+upJCAiPxJp0Dkz6wx0Amrt2lZYxy9JL5u259L/2QksXL2Zp/tn0aONkoCI/FiUnsV3Ar0JEsFo4BTgU0CJII1t25nHFUMnMGPpep68qBvHHqQ2AREpXJR+BOcR9Pxd4e4DCDp81Yw1KtkjO3Lzv5tk/q+/6MJPD9bTQSJStCiJYKu75wO5ZlYPWAUcGG9Ysrty8/K5/sXJjJ2zmvvOPoS+XTXJvIgUL0obwcRwuOingEnAJuCLOIOS3ZOf7/z21Wm8NWMFt5/2E/r10AB9IlKyKMNQXxsuDg57Addz92nxhiWl5R6MIvpa9lJuPPkgruilQpuIRFNch7JCO5Lt2qcOZenD3bn/7S8ZNm4xvzr2QAad0C7pkESkAimuRFBYR7Jd1KEsjTz+4Xz+8dFCLj6iJbeeoqGkRaR0iutQpo5kFcA/P/2Kh96byzndmnHPmZ2VBESk1KL0I6gFXAscQ1AS+AQY7O7bYo5NSvDiF4u5981ZnNJ5f/587qFU0cxiIrIbojw19DywEXgsXO8H/Av4eVxBScn+M2Upvxs5nd4dmvDIBYdRTXMMi8huipIIOrh7l5T1MWY2Na6ApGTvzlzBjf+eSs82jRh88eHUqKYkICK7L8pfkMlmdsSuFTPrCfwvvpCkOJ/MW811IyZzSLP6PN2/O7WqV006JBGp4KKUCHoCl5jZ4nC9JTDbzKYTzFR2aGzRyQ9MWLSWK5+fyIFN6jB0QA/2rhlpzEARkWJF+UvSJ/YopERzVmzksmcn0LTBXvzr8p7Ur1096ZBEpJKIkgjau/v7qRvMrL+7D40pJilgy45cBo7Ipmb1qgy/oidN6mrMPxEpO1HaCO4wsyfNrI6Z7WdmbwBnxB2YfO8Pr89kwepNPHJBVw6ov1fS4YhIJRMlERwHLACmEMxDMMLdz4szKPneK5NyeDU7h0EntOfodo2TDkdEKqEoiaAhQYPxAmA70MrUfbVczFu5kT+8PoMjDmzE9Se2TzocEamkoiSCccBb7t4H6A40RY+Pxm7rjjwGjsimdo2qPHLBYVRVr2ERiUmUxuKT3H0xgLtvBX5tZsfGG5bcNWom81ZtYuiAHuxXr1bJLxAR2U1RSgRrzOwPZvYUgJm1B+rFG1Zme33yUl6auIRre7fVXMMiErsoieBZgraBI8P1HOCPsUWU4Ras3sTvR06ne+uG3HDSQUmHIyIZIEoiaOvufwZ2wnfVQ6qwjsG2nXkMHJ5NzWpVeLSfBpITkfIRpY1gh5ntRTAENWbWlqCEIGXs3jdn8eWKjTx7aXf1FxCRchMlEdwJvA20MLPhwNHApXEGlYnenLaM4eODqSaP77hv0uGISAaJMnn9e2aWDRxBUCV0vbuviT2yDLJozWZufXU63Vo24KafdUg6HBHJMJGGr3T3b4D/xhxLRtqem8d1L2RTtYrx2IXdqK52AREpZxrHOGH3/Xc2M5Zu4KlLsmjWQO0CIlL+9PUzQW9NX87Qz7/m8mPacHKn/ZIOR0QyVKREYGbHmNmAcLmJmbWJN6zKb/E3W/jtq9Po0rw+t/TpmHQ4IpLBSkwEZnYncAvwu3BTdWBYnEFVdjty8xn0QjYAj1/YTXMOi0iiovwFOhs4E9gM4O7LgLpxBlXZ3f/Wl0zNWc+D5x1Ki0a1kw5HRDJclESww92d7zuU1Yk3pMrtvVkreeZ/X9H/yFb06XxA0uGIiERKBP82s38ADczsSuB94Kl4w6qccr7dwk0vT6Vzs3r8/rSfJB2OiAgQrUPZX8zsZGAD0AG4w93fiz2ySmZnXj6DXphMXr7zeL9u1KxWNemQRESAaI3FNwCz3f1md7+pNEnAzPqY2Rwzm29mtxZzXHczyzOzSjsF5pNjFzB58Tr+3zmH0LqxatdEJH1EqRqqB7xjZp+Y2UAzi/TAu5lVBZ4ATgE6Af3MrFMRxz0AvBM97Ipl/qqNPP7hfE4/9ADO6NI06XBERH6gxETg7ne7+8HAQIJpKj8ys/cjnLsHMN/dF7r7DuBFoG8hxw0CXgVWRQ+74sjPd255dTq1a1blrjMPTjocEZEfKc0D7KuAFcA3QJThMZsBS1LWc8Jt3zGzZgSPpw4uRRwVyrDxXzPp62/5w2mdaLx3zaTDERH5kShtBNeY2VjgA6AxcKW7Hxrh3IVNXuMF1h8GbnH3vBJiuMrMJprZxNWrV0e4dHpYum4rD7z1Jb3aN+acbs1KfoGISAKiDDrXCviNu08p5blzgBYp682BZQWOyQJeNDMIksypZpbr7q+nHuTuQ4AhAFlZWQWTSVpyd24fOZ18h/vOPoTwPYqIpJ0iE4GZ1XP3DcCfw/VGqfvdfW0J554AtA/HJVoKXABcWOAc341ZZGbPAW8WTAIV1aipyxgzZzV/OL2Teg+LSForrkQwAjgdmERQpZP6ldaBA4s7sbvnmtl1BE8DVQWecfeZZnZ1uL/Stgus3byDu9+YRdcWDbj0qNZJhyMiUqwiE4G7nx7+3u2RRt19NDC6wLZCE4C7X7q710k397wxk43bdvLAuYdStYqqhEQkvUVpLP4gyjYJjJmzitenLOOa3u3osL/G5hOR9FdcG0EtoDbQ2Mwa8n3VUD2C/gRSwKbtudw+cgbt9t2bgce3TTocEZFIimsj+BXwG4I/+pP4PhFsIOgxLAX85Z05LFu/lVeuPlJjCYlIhVFcG8EjwCNmNsjdHyvHmCqkSV9/y9DPF3HJEa04vFWjkl8gIpImoow++piZdSYYL6hWyvbn4wysItmem8ctr07jgHq1uFnTTopIBVNiIginquxNkAhGEwwi9ymgRBB6YswC5q/axLMDurN3zSh99ERE0keUsYbOA04EVrj7AKALoEFzQnNWbOTJsfM5q2tTju8QZQgmEZH0EiURbHX3fCDXzOoRDD5XbGeyTJGX79zy6jTq1qrOHWdoZFERqZii1GNMNLMGBNNTTgI2AV/EGVRFMfSzRUxZso6Hz+9Kozo1kg5HRGS3RGksvjZcHGxmbwP13H1avGGlvyVrt/DgO3Po3aEJfbuqW4WIVFzFdSjrVtw+d8+OJ6T05+78fuR0qhj8SSOLikgFV1yJ4KFi9jlwQhnHUmG8lr2UT+at4e4zD6ZZg72SDkdEZI8U16Hs+PIMpKJYs2k79/53Foe3asgvj2iVdDgiInssSj+CSwrbnqkdyu5+YxZbtudx/zmHUEUji4pIJRDlqaHuKcu1CPoUZJOBHco+mL2SN6Yu44aTDqL9fhpZVEQqhyhPDQ1KXTez+sC/YosoTW3ctpPbX59Bh/3qck1vjSwqIpXH7oyHsAVoX9aBpLunPvmK5eu38cRF3ahRLUo/PBGRiiFKG8EbBE8JQdATuRPw7ziDSjfrtuzgmU+/4pTO+9OtZcOkwxERKVNRSgR/SVnOBb5295yY4klLT32ykM07cvnNSQclHYqISJmL0kbwEUA4zlC1cLmRu6+NOba0sHbzDp773yJOO+QATT0pIpVSlKqhq4B7ga1APsFMZU6GDDw35OOFbNmZx/UnZlyziIhkiChVQzcDB7v7mriDSTdrNm1n6GeLOLNLUz0uKiKVVpTHXxYQPCmUcYZ8vJDtuXn8WqUBEanEopQIfgd8Zmbjge27Nrr7r2OLKg2s2riN5z9fxFldm9G2yd5JhyMiEpsoieAfwIfAdII2gowweOxCduY5g1QaEJFKLkoiyHX3G2OPJI2s3LCNYeO/5pzDmtGmcZ2kwxERiVWUNoIxZnaVmR1gZo12/cQeWYKeHLuA/Hxn0AkqDYhI5RelRHBh+Pt3Kdsq7eOjy9dvZcT4xZx3eHNa7lM76XBERGIXpUNZm/IIJF08MWY+jjPw+HZJhyIiUi40H0GKnG+38NKEJfwiqwUtGqk0ICKZQfMRpHhizAIMU2lARDKK5iMILVm7hZcnLuHCni1pqnmIRSSD7M7A+pVyPoLHPpxHlSrGtb1VGhCRzKL5CIBFazbzavZSLjmyFfvXr5V0OCIi5UrzEQCPfTifalWMa47TFJQiknmKTARm1g7Yb9d8BCnbe5lZTXdfEHt05WDh6k2MnJzDZUe3Yd96Kg2ISOYpro3gYWBjIdu3hvsqhUc/mEfNalX5lUoDIpKhiksErd19WsGN7j4RaB1bROVo/qqNjJq6jEuObEWTujWTDkdEJBHFJYLi6kkqxfOVj3wwn1rVq3LVsZVytAwRkUiKSwQTzOzKghvN7HJgUnwhlY85Kzby5rRlXHpUa/bZW6UBEclcxT019BtgpJldxPd/+LOAGsDZUU5uZn2AR4CqwNPufn+B/RcBt4Srm4Br3H1q5Oj3wCMfzKVOjWpc2UulARHJbEUmAndfCRxlZscDncPN/3X3D6Oc2MyqAk8AJwM5BCWMUe4+K+Wwr4Dj3P1bMzsFGAL03I33USqzl29g9PQVDDqhHQ3r1Ij7ciIiaS3KEBNjgDG7ce4ewHx3XwhgZi8CfYHvEoG7f5Zy/Dig+W5cp9Qefn8udWtW44pjVBoQEdmdISaiagYsSVnPCbcV5XLgrcJ2hBPjTDSziatXr96joGYsXc87M1dyea821K9dfY/OJSJSGcSZCKyQbV7INsLqp8v5vr3ghy9yH+LuWe6e1aRJkz0K6uH351KvVjUuOyajplkQESlSnIkgB2iRst4cWFbwIDM7FHga6Ovu38QYD9Ny1vH+7FVc2etA6tVSaUBEBOJNBBOA9mbWxsxqABcAo1IPMLOWwGvAL919boyxAPC39+bSoHZ1Lj26ddyXEhGpMKIMOrdb3D3XzK4D3iF4fPQZd59pZleH+wcDdwD7AH83M4Bcd8+KI57sxd8yZs5qbv5ZB+qqNCAi8p3YEgGAu48GRhfYNjhl+QrgijhjSNWrfWP6H9W6vC4nIlIhxJoI0km3lg351+Wxd1EQEalw4mwjEBGRCkCJQEQkwykRiIhkOCUCEZEMp0QgIpLhlAhERDKcEoGISIZTIhARyXDmXuiAoGnLzFYDX+/myxsDa8ownLKW7vFB+seo+PaM4tsz6RxfK3cvdPjmCpcI9oSZTYxrLKOykO7xQfrHqPj2jOLbM+keX1FUNSQikuGUCEREMlymJYIhSQdQgnSPD9I/RsW3ZxTfnkn3+AqVUW0EIiLyY5lWIhARkQKUCEREMlylTARm1sfM5pjZfDO7tZD9ZmaPhvunmVm3coythZmNMbPZZjbTzK4v5JjeZrbezKaEP3eUV3zh9ReZ2fTw2hML2Z/k/euQcl+mmNkGM/tNgWPK/f6Z2TNmtsrMZqRsa2Rm75nZvPB3wyJeW+znNcb4HjSzL8N/w5Fm1qCI1xb7eYgxvrvMbGnKv+OpRbw2qfv3Ukpsi8xsShGvjf3+7TF3r1Q/BPMjLwAOBGoAU4FOBY45FXgLMOAIYHw5xncA0C1crgvMLSS+3sCbCd7DRUDjYvYndv8K+bdeQdBRJtH7BxwLdANmpGz7M3BruHwr8EAR76HYz2uM8f0UqBYuP1BYfFE+DzHGdxdwU4TPQCL3r8D+h4A7krp/e/pTGUsEPYD57r7Q3XcALwJ9CxzTF3jeA+OABmZ2QHkE5+7L3T07XN4IzAaalce1y1Bi96+AE4EF7r67Pc3LjLt/DKwtsLkvMDRcHgqcVchLo3xeY4nP3d9199xwdRzQvKyvG1UR9y+KxO7fLmZmwC+AF8r6uuWlMiaCZsCSlPUcfvyHNsoxsTOz1sBhwPhCdh9pZlPN7C0zO7h8I8OBd81skpldVcj+tLh/wAUU/Z8vyfu3y37uvhyCLwDAvoUcky738jKCUl5hSvo8xOm6sOrqmSKq1tLh/vUCVrr7vCL2J3n/IqmMicAK2VbwGdkox8TKzPYGXgV+4+4bCuzOJqju6AI8BrxenrEBR7t7N+AUYKCZHVtgfzrcvxrAmcDLhexO+v6VRjrcy9uAXGB4EYeU9HmIy5NAW6ArsJyg+qWgxO8f0I/iSwNJ3b/IKmMiyAFapKw3B5btxjGxMbPqBElguLu/VnC/u29w903h8migupk1Lq/43H1Z+HsVMJKg+J0q0fsXOgXIdveVBXckff9SrNxVZRb+XlXIMUl/FvsDpwMXeVihXVCEz0Ms3H2lu+e5ez7wVBHXTfr+VQPOAV4q6pik7l9pVMZEMAFob2Ztwm+NFwCjChwzCrgkfPrlCGD9riJ83ML6xH8Cs939r0Ucs394HGbWg+Df6Ztyiq+OmdXdtUzQoDijwGGJ3b8URX4LS/L+FTAK6B8u9wf+U8gxUT6vsTCzPsAtwJnuvqWIY6J8HuKKL7Xd6ewirpvY/QudBHzp7jmF7Uzy/pVK0q3VcfwQPNUyl+BpgtvCbVcDV4fLBjwR7p8OZJVjbMcQFF2nAVPCn1MLxHcdMJPgCYhxwFHlGN+B4XWnhjGk1f0Lr1+b4A97/ZRtid4/gqS0HNhJ8C31cmAf4ANgXvi7UXhsU2B0cZ/XcopvPkH9+q7P4eCC8RX1eSin+P4Vfr6mEfxxPyCd7l+4/bldn7uUY8v9/u3pj4aYEBHJcJWxakhEREpBiUBEJMMpEYiIZDglAhGRDKdEICKS4ZQIpFyYmZvZQynrN5nZXWV07ufM7LyyOFcJ1/m5BaPGjon7Wkkzs98nHYOUHyUCKS/bgXMS6uFbJDOrWorDLweudffj44onjSgRZBAlAikvuQTzud5QcEfBb/Rmtin83dvMPjKzf5vZXDO738wuMrMvwvHd26ac5iQz+yQ87vTw9VUtGHN/Qjhw2a9SzjvGzEYQdFgqGE+/8PwzzOyBcNsdBJ0BB5vZg4W85rfha6aa2f3htq5mNs6+H++/Ybh9rJn9zcw+DksY3c3sNQvmLfhjeExrC+YKGBq+/hUzqx3uO9HMJofXe8bMaobbF5nZ3WaWHe7rGG6vEx43IXxd33D7peF13w6v/edw+/3AXhaMnz88fP1/w/c2w8zOL8W/u1QESfdo009m/ACbgHoEY7PXB24C7gr3PQecl3ps+Ls3sI5gDoeawFLg7nDf9cDDKa9/m+CLTXuCnp+1gKuA28NjagITgTbheTcDbQqJsymwGGgCVAM+BM4K942lkF7UBOMefQbUDtd39SCeBhwXLt+TEu9YwrH/w/exLOU95hD0SG5N0AP96PC4Z8J7VougN/BB4fbnCQYuJLy3g8Lla4Gnw+X7gIvD5QYEvXDrAJcCC8N/j1rA10CL1H+DcPlc4KmU9fpJf570U7Y/KhFIufFglNXngV+X4mUTPJjDYTvBEALvhtunE/yx3OXf7p7vwVDAC4GOBOO6XGLBzFHjCf7Atg+P/8Ldvyrket2Bse6+2oOx+ocTTEpSnJOAZz0cr8fd15pZfaCBu38UHjO0wHl2jYczHZiZ8h4X8v0gakvc/X/h8jCCEkkH4Ct3n1vEeXcNYjiJ7+/PT4Fbw/swluCPfstw3wfuvt7dtwGzgFaFvL/pBCWuB8ysl7uvL+F+SAVTLekAJOM8TDBM9LMp23IJqynDweJqpOzbnrKcn7Kezw8/vwXHSnGCMZEGufs7qTvMrDdBiaAwhQ1rXBIr5PolSX0fBd/jrvdV1HuKct68lPMYcK67z0k90Mx6Frh26mu+v6j7XDM7nGBMn/9nZu+6+z0lxCEViEoEUq7cfS3wb4KG110WAYeHy32B6rtx6p+bWZWw3eBAYA7wDnCNBcN+Y2YHhSNAFmc8cJyZNQ4bkvsBH5XwmneBy1Lq8BuF35q/NbNe4TG/jHCeglqa2ZHhcj/gU+BLoLWZtSvFed8BBoVJFjM7LMK1d6bct6bAFncfBvyFYMpGqURUIpAkPEQwQuguTwH/MbMvCEbpLOrbenHmEPxB3I9gNMhtZvY0QfVIdvhHcDWFTxf5HXdfbma/A8YQfJMe7e6FDR+d+pq3zawrMNHMdgCjCZ666U/QuFyboMpnQCnf02ygv5n9g2AE0yfD9zUAeNmCsfAnAINLOM+9BCWxaeF9WEQwB0FxhoTHZxNU5z1oZvkEo29eU8r3IWlOo4+KpCELpjF90907Jx2LVH6qGhIRyXAqEYiIZDiVCEREMpwSgYhIhlMiEBHJcEoEIiIZTolARCTD/X8kY7RmBIo70wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the cumulative explained variance ratio\n",
    "cumulative_explained_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Plot the cumulative explained variance ratio\n",
    "plt.plot(cumulative_explained_variance_ratio)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the above graph I recommend 13 components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Insert comments>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "- Evaluate the target variable in the `df` object.  \n",
    "- Which metric would you use in evaluating a predictive model. Explain your choice in the markdown cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    0.496000\n",
      "2.0    0.253333\n",
      "1.0    0.250667\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Insert code here\n",
    "proportions = df['target'].value_counts(normalize=True)\n",
    "print(proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the target variable is roughly balanced, accuracy might be used as a measurement of this prediction model's performance. When the classes are balanced, accuracy, a straightforward and logical metric that assesses the percentage of instances in the test set that are properly identified, is appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "- Without using PCA, create a logistic regression model using practices discussed in class.  \n",
    "- Which model would you choose? Explain your results in the markdown cells.    \n",
    "- What is the accuracy, precision, and recall for the test data?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7033333333333334\n",
      "Precision: 0.6855872622001655\n",
      "Recall: 0.681410661265617\n"
     ]
    }
   ],
   "source": [
    "# Insert code here\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got an accuracy of 70 percent for this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "- Use PCA within a pipeline to create a logistic regression model using best practices from class.  \n",
    "- Which model performs the best on the training data? Explain your results in markdown cells.  \n",
    "- What is the accuracy, precision, and recall for the test data?\n",
    "- Does this perform better than the original logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n",
      "Precision: 0.6708589105614277\n",
      "Recall: 0.6610050824394097\n"
     ]
    }
   ],
   "source": [
    "# Insert code\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('pca', PCA(n_components=10, random_state=42)),\n",
    "    ('logreg', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test_scaled)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy (training): 0.725\n",
      "PCA + Logistic Regression accuracy (training): 0.7225\n"
     ]
    }
   ],
   "source": [
    "# Fit a logistic regression model to the training data without PCA\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = model.predict(X_train_scaled)\n",
    "accuracy_lr = accuracy_score(y_train, y_pred_lr)\n",
    "\n",
    "# Fit a logistic regression model with PCA to the training data\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "y_pred_pca = pipeline.predict(X_train_scaled)\n",
    "accuracy_pca = accuracy_score(y_train, y_pred_pca)\n",
    "\n",
    "print(\"Logistic Regression accuracy (training):\", accuracy_lr)\n",
    "print(\"PCA + Logistic Regression accuracy (training):\", accuracy_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy (test): 0.725\n",
      "PCA + Logistic Regression accuracy (test): 0.69\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression accuracy (test):\", accuracy_lr)\n",
    "print(\"PCA + Logistic Regression accuracy (test):\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On training data the accuracy of both the models are similar but on the test data original logistic regression model performed better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Without using PCA, create a decision tree model using best practices discussed in class.  \n",
    "- Which model performs the best on the training data? Explain your results in the markdown cells.  \n",
    "- What is the accuracy, precision, and recall for the test data?  \n",
    "- Does this perform better than either of the logistic regression models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 7, 'min_samples_split': 2}\n",
      "Accuracy: 0.7066666666666667\n",
      "Precision: 0.7065465983964435\n",
      "Recall: 0.7066666666666667\n"
     ]
    }
   ],
   "source": [
    "# Insert code here\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# create a decision tree model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# use grid search cross-validation to find the best hyperparameters\n",
    "params = {'max_depth': [3, 5, 7], 'min_samples_split': [2, 5, 10]}\n",
    "dt_grid = GridSearchCV(dt_model, params, cv=5)\n",
    "dt_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print the best hyperparameters\n",
    "print(\"Best hyperparameters:\", dt_grid.best_params_)\n",
    "\n",
    "# predict on the test set\n",
    "y_pred = dt_grid.predict(X_test_scaled)\n",
    "\n",
    "# evaluate the model performance\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of this model is than the accuracy of both the logistic regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "- Repeat `Question 5` but use PCA.  \n",
    "- Does this perform better than the original Decision Tree or the logistic regression models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'dt__max_depth': 7, 'dt__min_samples_split': 2, 'pca__n_components': 5}\n",
      "Accuracy: 0.67\n",
      "Precision: 0.6645238095238095\n",
      "Recall: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Insert code here\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# create a pipeline with PCA and a decision tree model\n",
    "pca_dt_pipeline = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "# use grid search cross-validation to find the best hyperparameters\n",
    "params = {\n",
    "    'pca__n_components': [2, 5, 10],\n",
    "    'dt__max_depth': [3, 5, 7],\n",
    "    'dt__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "pca_dt_grid = GridSearchCV(pca_dt_pipeline, params, cv=5)\n",
    "pca_dt_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print the best hyperparameters\n",
    "print(\"Best hyperparameters:\", pca_dt_grid.best_params_)\n",
    "\n",
    "# predict on the test set\n",
    "y_pred = pca_dt_grid.predict(X_test_scaled)\n",
    "\n",
    "# evaluate the model performance\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of this model is lesser than all the previous models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
